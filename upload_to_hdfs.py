#!/usr/bin/env python
# -*- coding: utf-8 -*-

import os
import subprocess
import sys
import time
from pyhdfs import HdfsClient
from config import Config

def check_hadoop_available():
    """æ£€æŸ¥Hadoopæ˜¯å¦å¯ç”¨"""
    try:
        # å°è¯•ping HDFS
        subprocess.run(["hadoop", "fs", "-ls", "/"], 
                       stdout=subprocess.PIPE, 
                       stderr=subprocess.PIPE, 
                       check=True,
                       shell=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        return False

def check_safe_mode():
    """æ£€æŸ¥HDFSæ˜¯å¦å¤„äºå®‰å…¨æ¨¡å¼"""
    try:
        result = subprocess.run("hadoop dfsadmin -safemode get", 
                               shell=True, 
                               stdout=subprocess.PIPE, 
                               stderr=subprocess.PIPE, 
                               universal_newlines=True)
        return "Safe mode is ON" in result.stdout
    except subprocess.CalledProcessError:
        return False

def leave_safe_mode():
    """å°è¯•é€€å‡ºå®‰å…¨æ¨¡å¼"""
    print("â„¹ï¸ æ­£åœ¨å°è¯•é€€å‡ºå®‰å…¨æ¨¡å¼...")
    try:
        result = subprocess.run("hadoop dfsadmin -safemode leave", 
                               shell=True, 
                               stdout=subprocess.PIPE, 
                               stderr=subprocess.PIPE, 
                               universal_newlines=True,
                               check=True)
        if "Safe mode is OFF" in result.stdout:
            print("âœ… å·²æˆåŠŸé€€å‡ºå®‰å…¨æ¨¡å¼")
            return True
        else:
            print(f"âš ï¸ æ— æ³•ç¡®è®¤å®‰å…¨æ¨¡å¼çŠ¶æ€: {result.stdout}")
            return False
    except subprocess.CalledProcessError as e:
        print(f"âŒ é€€å‡ºå®‰å…¨æ¨¡å¼å¤±è´¥: {e}")
        return False

def create_hdfs_dirs():
    """åˆ›å»ºHDFSç›®å½•ç»“æ„"""
    # æ£€æŸ¥å®‰å…¨æ¨¡å¼
    if check_safe_mode():
        print("âš ï¸ HDFSå½“å‰å¤„äºå®‰å…¨æ¨¡å¼ï¼Œå°è¯•é€€å‡º...")
        if not leave_safe_mode():
            print("âœ³ï¸ æç¤º: å¦‚æœæ‚¨æ²¡æœ‰ç®¡ç†å‘˜æƒé™ï¼Œå¯èƒ½éœ€è¦ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œæˆ–ç­‰å¾…å®‰å…¨æ¨¡å¼è‡ªåŠ¨é€€å‡º")
            print("âœ³ï¸ æ‚¨å¯ä»¥å°è¯•æ‰‹åŠ¨æ‰§è¡Œ: hadoop dfsadmin -safemode leave")
            user_input = input("æ˜¯å¦ç»§ç»­å°è¯•åˆ›å»ºç›®å½•? (y/n): ")
            if user_input.lower() != 'y':
                return False
    
    try:
        cmd = f"hadoop fs -mkdir -p {Config.HDFS_BASE_PATH}"
        subprocess.run(cmd, shell=True, check=True)
        print(f"âœ… å·²åˆ›å»ºHDFSåŸºç¡€ç›®å½•: {Config.HDFS_BASE_PATH}")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ åˆ›å»ºHDFSç›®å½•å¤±è´¥: {e}")
        
        # å¦‚æœå¤±è´¥ï¼Œæ£€æŸ¥é”™è¯¯æ˜¯å¦æ˜¯æƒé™é—®é¢˜
        if "Permission denied" in str(e):
            print("âš ï¸ å¯èƒ½æ˜¯æƒé™é—®é¢˜ï¼Œè¯·ç¡®ä¿æ‚¨æœ‰æƒé™å†™å…¥HDFS")
        elif "Name node is in safe mode" in str(e):
            print("âš ï¸ Hadoopä»å¤„äºå®‰å…¨æ¨¡å¼ï¼Œæ— æ³•åˆ›å»ºç›®å½•")
            print("âœ³ï¸ æç¤º: æ‚¨å¯ä»¥ç­‰å¾…ä¸€æ®µæ—¶é—´å†å°è¯•ï¼Œå®‰å…¨æ¨¡å¼é€šå¸¸ä¼šè‡ªåŠ¨é€€å‡º")
            print("âœ³ï¸ æˆ–è€…ä»¥ç®¡ç†å‘˜èº«ä»½è¿è¡Œ: hadoop dfsadmin -safemode leave")
        
        return False

def upload_file_to_hdfs(local_path, hdfs_path):
    """å°†æœ¬åœ°æ–‡ä»¶ä¸Šä¼ åˆ°HDFS"""
    try:
        cmd = f'hadoop fs -put -f "{local_path}" "{hdfs_path}"'
        subprocess.run(cmd, shell=True, check=True)
        file_size = os.path.getsize(local_path) / 1024  # KB
        print(f"âœ… å·²ä¸Šä¼ : {os.path.basename(local_path)} ({file_size:.2f} KB)")
        return True
    except subprocess.CalledProcessError as e:
        print(f"âŒ ä¸Šä¼ å¤±è´¥ {os.path.basename(local_path)}: {e}")
        return False

def check_hdfs_file_exists(hdfs_path):
    """æ£€æŸ¥HDFSæ–‡ä»¶æ˜¯å¦å­˜åœ¨"""
    try:
        cmd = f'hadoop fs -test -e "{hdfs_path}"'
        result = subprocess.run(cmd, shell=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)
        return result.returncode == 0
    except Exception:
        return False

def upload_data_directory():
    """ä¸Šä¼ dataç›®å½•ä¸­çš„æ‰€æœ‰Excelæ–‡ä»¶åˆ°HDFS"""
    if not check_hadoop_available():
        print("âŒ æ— æ³•è¿æ¥åˆ°Hadoopã€‚è¯·ç¡®ä¿HadoopæœåŠ¡å·²å¯åŠ¨ã€‚")
        return False
    
    print("â„¹ï¸ HadoopæœåŠ¡å·²è¿æ¥")
    
    if not create_hdfs_dirs():
        return False
    
    # è·å–æœ¬åœ°æ•°æ®æ–‡ä»¶åˆ—è¡¨
    data_dir = Config.DATA_DIR
    if not os.path.exists(data_dir):
        print(f"âŒ æœ¬åœ°æ•°æ®ç›®å½•ä¸å­˜åœ¨: {data_dir}")
        return False
    
    files = [f for f in os.listdir(data_dir) 
             if f.endswith(('.xls', '.xlsx')) and os.path.isfile(os.path.join(data_dir, f))]
    
    if not files:
        print(f"âš ï¸ æœªåœ¨ {data_dir} ä¸­æ‰¾åˆ°Excelæ–‡ä»¶")
        return False
    
    print(f"â„¹ï¸ å‘ç° {len(files)} ä¸ªExcelæ–‡ä»¶ï¼Œå‡†å¤‡ä¸Šä¼ ...")
    
    # ä¸Šä¼ æ–‡ä»¶åˆ°HDFS
    successful_uploads = 0
    for filename in files:
        local_path = os.path.join(data_dir, filename)
        hdfs_path = f"{Config.HDFS_BASE_PATH}/{filename}"
        
        if upload_file_to_hdfs(local_path, hdfs_path):
            successful_uploads += 1
    
    print(f"\nğŸ‰ ä¸Šä¼ å®Œæˆ! æˆåŠŸä¸Šä¼  {successful_uploads}/{len(files)} ä¸ªæ–‡ä»¶åˆ° {Config.HDFS_BASE_PATH}")
    print(f"ğŸ“‹ å¯ä»¥é€šè¿‡ä»¥ä¸‹å‘½ä»¤æŸ¥çœ‹æ–‡ä»¶åˆ—è¡¨:")
    print(f"   hadoop fs -ls {Config.HDFS_BASE_PATH}")
    
    return successful_uploads == len(files)

def use_local_mode_fallback():
    """åˆ›å»ºä¸€ä¸ªä½¿ç”¨æœ¬åœ°æ¨¡å¼çš„é…ç½®å¤‡ä»½ï¼Œä»¥é˜²HDFSæ— æ³•è®¿é—®"""
    print("â„¹ï¸ æ­£åœ¨ä¸ºSparkåˆ›å»ºæœ¬åœ°æ¨¡å¼å¤‡ä»½é€‰é¡¹...")
    
    # åˆ›å»ºå¤‡ä»½ç›®å½•
    local_data_dir = os.path.join(os.path.dirname(Config.BASE_DIR), 'local_data_backup')
    os.makedirs(local_data_dir, exist_ok=True)
    
    # å°†åæ–œæ æ›¿æ¢ä¸ºæ­£æ–œæ 
    local_data_dir_path = local_data_dir.replace('\\', '/')
    
    # æ›´æ–°é…ç½®æ–‡ä»¶
    with open(os.path.join(os.path.dirname(Config.BASE_DIR), 'local_mode.py'), 'w') as f:
        f.write(f"""
# æœ¬åœ°æ¨¡å¼é…ç½®ï¼Œå½“HDFSä¸å¯ç”¨æ—¶ä½¿ç”¨
LOCAL_DATA_DIR = '{local_data_dir_path}'
USE_LOCAL_MODE = True  # è®¾ç½®ä¸ºTrueè¡¨ç¤ºä½¿ç”¨æœ¬åœ°æ¨¡å¼
""")
    
    print(f"âœ… å·²åˆ›å»ºæœ¬åœ°æ¨¡å¼å¤‡ä»½é…ç½®: {local_data_dir}")
    print("âœ³ï¸ å¦‚æœéœ€è¦ä½¿ç”¨æœ¬åœ°æ¨¡å¼ï¼Œè¯·åœ¨åº”ç”¨ä¸­å¯¼å…¥local_modeå¹¶æ£€æŸ¥USE_LOCAL_MODEæ ‡å¿—")

if __name__ == "__main__":
    print("ğŸš€ å¼€å§‹å°†åˆ¶é€ ä¸šæ•°æ®ä¸Šä¼ åˆ°HDFS...")
    
    # å¦‚æœç¬¬ä¸€æ¬¡å°è¯•å¤±è´¥ï¼Œè¯¢é—®æ˜¯å¦ä½¿ç”¨æœ¬åœ°æ¨¡å¼
    if not upload_data_directory():
        print("\nâš ï¸ HDFSä¸Šä¼ é‡åˆ°é—®é¢˜")
        user_input = input("æ‚¨å¸Œæœ›ä¸ºåº”ç”¨åˆ›å»ºæœ¬åœ°æ¨¡å¼å¤‡ä»½å—? (y/n): ")
        if user_input.lower() == 'y':
            use_local_mode_fallback()
    
    print("\nâœ¨ å®Œæˆ! æ‚¨å¯ä»¥è¿è¡Œåº”ç”¨ç¨‹åºæˆ–æŸ¥çœ‹HDFSä¸Šçš„æ•°æ®ã€‚") 